import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from PIL import Image
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ö–û–ù–°–¢–ê–ù–¢–´ ---
mp_face_mesh = mp.solutions.face_mesh

# <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 1: –ò–ó–ú–ï–ù–ò–õ–ò–°–¨ –ö–õ–Æ–ß–ï–í–´–ï –¢–û–ß–ö–ò >>>
# –¢–µ–ø–µ—Ä—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
# 168: –¢–æ—á–∫–∞ –º–µ–∂–¥—É –±—Ä–æ–≤—è–º–∏ (Nasion) - –∏–¥–µ–∞–ª—å–Ω—ã–π —è–∫–æ—Ä—å –¥–ª—è –æ—á–∫–æ–≤
# 234, 454: –í–∏—Å–∫–∏ (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —à–∏—Ä–∏–Ω—ã –∏ –Ω–∞–∫–ª–æ–Ω–∞)
KEY_POINTS_GLASSES = [168, 234, 454] 

# –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–º–∫–∏ (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)
COLOR_RED = (0, 0, 255)
COLOR_GREEN = (0, 255, 0)

# <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 2: –£–î–ê–õ–ï–ù–ê –ù–ï–ù–ê–î–ï–ñ–ù–ê–Ø –ö–û–ù–°–¢–ê–ù–¢–ê VERTICAL_OFFSET_FACTOR >>>
# –ú—ã –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–¥–∞–µ–º—Å—è –≤ –Ω–µ–π, —Ç–∞–∫ –∫–∞–∫ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ø–µ—Ä—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ.

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def overlay_glasses(face_image, glasses_image, vertical_offset=0):
    face_cv = np.array(face_image.convert('RGB'))
    face_cv = cv2.cvtColor(face_cv, cv2.COLOR_RGB2BGR)
    output_image = face_cv.copy()
    
    with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:
        results = face_mesh.process(output_image)
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                h, w, _ = face_cv.shape
                
                # <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 3: –ò–°–ü–û–õ–¨–ó–£–ï–ú –ù–û–í–´–ï –¢–û–ß–ö–ò –î–õ–Ø –ê–í–¢–û–ü–û–î–ì–û–ù–ö–ò >>>
                nasion_point = (int(face_landmarks.landmark[KEY_POINTS_GLASSES[0]].x * w), int(face_landmarks.landmark[KEY_POINTS_GLASSES[0]].y * h))
                left_temple = (int(face_landmarks.landmark[KEY_POINTS_GLASSES[1]].x * w), int(face_landmarks.landmark[KEY_POINTS_GLASSES[1]].y * h))
                right_temple = (int(face_landmarks.landmark[KEY_POINTS_GLASSES[2]].x * w), int(face_landmarks.landmark[KEY_POINTS_GLASSES[2]].y * h))
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∏—Ä–∏–Ω—É –∏ —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –ø–æ –≤–∏—Å–∫–∞–º
                scale_factor = 1.05
                glasses_width = int(np.linalg.norm(np.array(left_temple) - np.array(right_temple)))
                glasses_width = int(glasses_width * scale_factor)
                
                angle_rad = np.arctan2(right_temple[1] - left_temple[1], right_temple[0] - left_temple[0])
                angle_deg = np.degrees(angle_rad)
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏ –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—á–∫–æ–≤
                original_glasses_w, original_glasses_h = glasses_image.size
                aspect_ratio = original_glasses_h / original_glasses_w
                new_h = int(glasses_width * aspect_ratio)
                
                if new_h == 0 or glasses_width == 0:
                    return None
                
                resized_glasses = glasses_image.resize((glasses_width, new_h))
                rotated_glasses = resized_glasses.rotate(-angle_deg, expand=True, resample=Image.BICUBIC)
                
                rotated_w, rotated_h = rotated_glasses.size
                
                # <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 4: –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –†–ê–°–ß–ï–¢–ê –ü–û–õ–û–ñ–ï–ù–ò–Ø (–ê–í–¢–û–ü–û–î–ì–û–ù–ö–ê) >>>
                # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –æ—á–∫–∏ –ø–æ —Ç–æ—á–∫–µ –º–µ–∂–¥—É –±—Ä–æ–≤—è–º–∏ (nasion_point)
                paste_x = nasion_point[0] - rotated_w // 2
                paste_y = nasion_point[1] - rotated_h // 2
                
                # <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 5: –ü–†–ò–ú–ï–ù–Ø–ï–ú –†–£–ß–ù–£–Æ –ö–û–†–†–ï–ö–¢–ò–†–û–í–ö–£ –û–¢ –°–õ–ê–ô–î–ï–†–ê >>>
                paste_y += vertical_offset
                
                # –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                output_pil = Image.fromarray(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))
                output_pil.paste(rotated_glasses, (paste_x, paste_y), rotated_glasses)
                return output_pil
    return None

# --- –ö–õ–ê–°–° –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –í–ò–î–ï–û –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò ---
class FaceAlignmentProcessor(VideoProcessorBase):
    def __init__(self):
        self.face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)
        self.latest_good_frame = None

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        image = frame.to_ndarray(format="bgr24")
        h, w, _ = image.shape
        
        oval_center = (w // 2, h // 2)
        oval_axes = (int(w * 0.3), int(h * 0.4))
        
        results = self.face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        is_ready = False
        message = "–ü–æ–º–µ—Å—Ç–∏—Ç–µ –ª–∏—Ü–æ –≤ —Ä–∞–º–∫—É"
        frame_color = COLOR_RED

        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–æ–∂–µ–Ω–∏—è –≤ –∫–∞–¥—Ä–µ
                left_temple = face_landmarks.landmark[KEY_POINTS_GLASSES[1]]
                right_temple = face_landmarks.landmark[KEY_POINTS_GLASSES[2]]
                
                angle_rad = np.arctan2(right_temple.y - left_temple.y, right_temple.x - left_temple.x)
                angle_deg = abs(np.degrees(angle_rad))
                
                face_width_ratio = np.linalg.norm([right_temple.x - left_temple.x, right_temple.y - left_temple.y])

                if angle_deg > 10:
                    message = "–í—ã—Ä–æ–≤–Ω—è–π—Ç–µ –≥–æ–ª–æ–≤—É"
                elif face_width_ratio < 0.3:
                    message = "–ü–æ–¥–≤–∏–Ω—å—Ç–µ—Å—å –±–ª–∏–∂–µ"
                elif face_width_ratio > 0.6:
                    message = "–ü–æ–¥–≤–∏–Ω—å—Ç–µ—Å—å –¥–∞–ª—å—à–µ"
                else:
                    message = "–û—Ç–ª–∏—á–Ω–æ! –ú–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫"
                    frame_color = COLOR_GREEN
                    is_ready = True
        
        cv2.ellipse(image, oval_center, oval_axes, 0, 0, 360, frame_color, 3)

        # <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 6: –ë–û–õ–ï–ï –£–ó–ö–ê–Ø –ó–û–ù–ê –î–õ–Ø –ì–õ–ê–ó >>>
        line_width = oval_axes[0]
        line_start_x = oval_center[0] - line_width
        line_end_x = oval_center[0] + line_width
        
        # –°–¥–µ–ª–∞–ª–∏ –∑–æ–Ω—É —É–∂–µ. –í–µ—Ä—Ö–Ω—è—è –ª–∏–Ω–∏—è —á—É—Ç—å –Ω–∏–∂–µ, –Ω–∏–∂–Ω—è—è —á—É—Ç—å –≤—ã—à–µ.
        eye_line_top_y = oval_center[1] - int(oval_axes[1] * 0.25)
        eye_line_bottom_y = oval_center[1] + int(oval_axes[1] * 0.0)

        cv2.line(image, (line_start_x, eye_line_top_y), (line_end_x, eye_line_top_y), frame_color, 1)
        cv2.line(image, (line_start_x, eye_line_bottom_y), (line_end_x, eye_line_bottom_y), frame_color, 1)

        cv2.putText(image, message, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, frame_color, 2)

        if is_ready:
            self.latest_good_frame = image.copy()
        else:
            self.latest_good_frame = None

        return av.VideoFrame.from_ndarray(image, format="bgr24")


# --- –ò–ù–¢–ï–†–§–ï–ô–° STREAMLIT ---
st.set_page_config(layout="wide", page_title="–í–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–∏–º–µ—Ä–∫–∞ –æ—á–∫–æ–≤")
st.title("–ü—Ä–æ—Ç–æ—Ç–∏–ø —Å–µ—Ä–≤–∏—Å–∞ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ –æ—á–∫–æ–≤ üëì")

if "photo" not in st.session_state:
    st.session_state.photo = None

col1, col2 = st.columns([0.6, 0.4])

with col1:
    st.header("–®–∞–≥ 1: –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
    
    if st.session_state.photo is None:
        webrtc_ctx = webrtc_streamer(
            key="face-alignment",
            video_processor_factory=FaceAlignmentProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

        if st.button("–°–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫"):
            if webrtc_ctx.video_processor and webrtc_ctx.video_processor.latest_good_frame is not None:
                st.session_state.photo = webrtc_ctx.video_processor.latest_good_frame
                st.rerun()
            else:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à–µ –ª–∏—Ü–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∑–µ–ª–µ–Ω–æ–π —Ä–∞–º–∫–µ.")
    
    else:
        st.success("–û—Ç–ª–∏—á–Ω–æ–µ —Ñ–æ—Ç–æ!")
        st.image(st.session_state.photo, channels="BGR", caption="–í–∞—à–µ —Ñ–æ—Ç–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∫–∏")
        if st.button("–°–¥–µ–ª–∞—Ç—å –Ω–æ–≤–æ–µ —Ñ–æ—Ç–æ"):
            st.session_state.photo = None
            st.rerun()

with col2:
    st.header("–®–∞–≥ 2: –í—ã–±–µ—Ä–∏—Ç–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –æ—á–∫–∏")

    uploaded_glasses_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ PNG —Ñ–∞–π–ª —Å –æ—á–∫–∞–º–∏", type=["png"])
    
    # <<< –ò–ó–ú–ï–ù–ï–ù–ò–ï 7: –î–û–ë–ê–í–õ–ï–ù –°–õ–ê–ô–î–ï–† –î–õ–Ø –†–£–ß–ù–û–ô –ü–û–î–°–¢–†–û–ô–ö–ò >>>
    manual_offset = st.slider(
        "–ü–æ–¥–Ω—è—Ç—å / –û–ø—É—Å—Ç–∏—Ç—å –æ—á–∫–∏",
        min_value=-50,  # –ú–æ–∂–Ω–æ –æ–ø—É—Å—Ç–∏—Ç—å –Ω–∞ 50 –ø–∏–∫—Å–µ–ª–µ–π
        max_value=50,   # –ú–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å –Ω–∞ 50 –ø–∏–∫—Å–µ–ª–µ–π
        value=0,        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ —Å–º–µ—â–µ–Ω–∏—è
        step=1,
        help="–î–≤–∏–≥–∞–π—Ç–µ —Å–ª–∞–π–¥–µ—Ä, —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ –ø–æ–¥–æ–≥–Ω–∞—Ç—å –ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—á–∫–æ–≤ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏."
    )

    if st.session_state.photo is not None and uploaded_glasses_file is not None:
        st.divider()
        st.header(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–º–µ—Ä–∫–∏: ¬´{uploaded_glasses_file.name}¬ª")
        
        face_pil_image = Image.fromarray(cv2.cvtColor(st.session_state.photo, cv2.COLOR_BGR2RGB))
        glasses_pil_image = Image.open(uploaded_glasses_file).convert("RGBA")

        with st.spinner('–ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –æ—á–∫–∏...'):
            # –ü–µ—Ä–µ–¥–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞ –≤ —Ñ—É–Ω–∫—Ü–∏—é
            result_image = overlay_glasses(face_pil_image, glasses_pil_image, vertical_offset=manual_offset)

        if result_image:
            st.image(result_image, caption="–í–æ—Ç –∫–∞–∫ –≤—ã –±—É–¥–µ—Ç–µ –≤—ã–≥–ª—è–¥–µ—Ç—å!")
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ. –í–æ–∑–º–æ–∂–Ω–æ, –ª–∏—Ü–æ –Ω–∞ —Å–Ω–∏–º–∫–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –Ω–µ—á–µ—Ç–∫–æ.")
    elif st.session_state.photo is not None:
        st.info("–¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—á–∫–∞–º–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –∏—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")
    else:
        st.info("–°–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä–∫—É.")
